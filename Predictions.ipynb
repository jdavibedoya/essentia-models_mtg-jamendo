{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Predictions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jdavibedoya/essentia-models_mtg-jamendo/blob/master/Predictions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUjBy-0PVkBX",
        "colab_type": "text"
      },
      "source": [
        "This notebook computes predictions for 11 classifications tasks using two source tasks, namely MUSICNN_MSD and VGGish_AudioSet. More detailed information on the models used can be found here: [A collection of TensorFlow models for Essentia](https://mtg.github.io/essentia-labs//news/2020/01/16/tensorflow-models-released/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-YuzPCJYsE3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# installing packages and downloading models\n",
        "\n",
        "# install essentia-tensorflor\n",
        "%pip install essentia-tensorflow -f https://essentia.upf.edu/python-wheels/\n",
        "\n",
        "# download models\n",
        "#!wget -N -P drive/Shared\\ drives/AMPLAB\\ Project/models/ -i drive/Shared\\ drives/AMPLAB\\ Project/models/Models.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHchLWsrZcZf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imports\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "from essentia.standard import *\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "main_dir = \"drive/Shared drives/AMPLAB Project/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeoX8TlyY89Z",
        "colab_type": "text"
      },
      "source": [
        "This cell computes the predictions for the source task `musicnn_msd`. This predictions are stored in the `predictions/musicnn_msd/` folder in a format similar to that used of the annotations, however this time two values $[a_0, a_1]$ are stored because the output layer of the architecture of the transfer learning classifiers consists of 2 units with sigmoid activations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8z4SqPvfImv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# computing predictions - musicnn_msd\n",
        "\n",
        "# directories\n",
        "main_dir = \"drive/Shared drives/AMPLAB Project/\"\n",
        "models_dir = main_dir + \"models/\"\n",
        "predictions_dir = main_dir + \"predictions/musicnn_msd/\"\n",
        "annotations_dir = main_dir + \"annotations/\"\n",
        "\n",
        "# target tasks by group\n",
        "mood = [\"mood_acoustic\", \"mood_electronic\", \"mood_aggressive\", \"mood_relaxed\", \"mood_happy\", \"mood_sad\", \"mood_party\"]\n",
        "miscellaneous = [\"tonal_atonal\", \"danceability\", \"voice_instrumental\", \"gender\"]\n",
        "\n",
        "# set with the names of the annotation files\n",
        "file_names = set()\n",
        "for root, dirs, files in os.walk(annotations_dir):\n",
        "    for file in files:\n",
        "        if file.endswith('.json'):\n",
        "            file_name = \"-\".join( file.split('-')[1:] )\n",
        "            file_names.add(file_name)\n",
        "\n",
        "# compute and store predictions for each audio sample\n",
        "for file_name in file_names:\n",
        "    if os.path.exists(predictions_dir + 'mood-' + file_name) and os.path.exists(predictions_dir + 'miscellaneous-' + file_name): # avoid recomputing\n",
        "        continue\n",
        "    # string manipulations to locate the audio file\n",
        "    file_name_dir = file_name.split('-')[-1].split('_')[0]\n",
        "    file_name_audio = file_name.split('_')[-1].split('.json')[0] \n",
        "    file_name_path = main_dir + \"17/\" + file_name_dir + \"/\" + file_name_audio\n",
        "\n",
        "    audio = EasyLoader(filename = file_name_path, sampleRate = 16000, endTime = 180)() # load audio\n",
        "\n",
        "    predictions_mood = {}\n",
        "    predictions_miscellaneous = {}\n",
        "    for root, dirs, files in os.walk(models_dir): # get model names\n",
        "        for file in files:\n",
        "              if file.endswith('musicnn-msd.pb'): # select source task\n",
        "                  model_name = os.path.join(root, file)\n",
        "                  model = file.split('-')[0]\n",
        "                  prediction = TensorflowPredictMusiCNN(graphFilename = model_name)(audio) # compute prediction using MusiCNN model\n",
        "                  prediction = np.mean(prediction, axis=0)\n",
        "                  # store predictions by groups \n",
        "                  if model in mood:\n",
        "                      predictions_mood[model] = prediction.tolist()\n",
        "                  elif model in miscellaneous:\n",
        "                      predictions_miscellaneous[model] = prediction.tolist()\n",
        "                  else:\n",
        "                      raise Exception(\"Invalid model\")\n",
        "\n",
        "    # create json files with predictions\n",
        "    with open(predictions_dir + 'mood-' + file_name, 'w') as json_file_prediction:\n",
        "        json.dump(predictions_mood, json_file_prediction)\n",
        "    with open(predictions_dir + 'miscellaneous-' + file_name, 'w') as json_file_prediction: \n",
        "        json.dump(predictions_miscellaneous, json_file_prediction)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jkxbna0FbM_b",
        "colab_type": "text"
      },
      "source": [
        "The next cell indicates the number of predictions that have been computed and stored so far."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3Np0i1kLtWZ",
        "colab_type": "code",
        "outputId": "8d6fdb00-79b8-47bb-a4e8-b1e561711d5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# number of musicnn_msd prediction files per target task group\n",
        "predictions_dir = main_dir + \"predictions/musicnn_msd/\"\n",
        "print( '{} musicnn_msd predictions stored'.format( len(os.listdir(predictions_dir))//2 ) )"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "565 musicnn_msd predictions stored\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLcy9zXxaaNl",
        "colab_type": "text"
      },
      "source": [
        "This cell computes the predictions for the source task `vggish_audioset`.\n",
        "This predictions are stored in the `predictions/vggish_audioset/` folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mX7tCHJMVh9o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# computing predictions - vggish_audioset\n",
        "\n",
        "# directories\n",
        "main_dir = \"drive/Shared drives/AMPLAB Project/\"\n",
        "models_dir = main_dir + \"models/\"\n",
        "predictions_dir = main_dir + \"predictions/vggish_audioset/\"\n",
        "annotations_dir = main_dir + \"annotations/\"\n",
        "\n",
        "# target tasks by group\n",
        "mood = [\"mood_acoustic\", \"mood_electronic\", \"mood_aggressive\", \"mood_relaxed\", \"mood_happy\", \"mood_sad\", \"mood_party\"]\n",
        "miscellaneous = [\"tonal_atonal\", \"danceability\", \"voice_instrumental\", \"gender\"]\n",
        "\n",
        "# set with the names of the annotation files\n",
        "file_names = set()\n",
        "for root, dirs, files in os.walk(annotations_dir):\n",
        "    for file in files:\n",
        "        if file.endswith('.json'):\n",
        "            file_name = \"-\".join( file.split('-')[1:] )\n",
        "            file_names.add(file_name)\n",
        "\n",
        "# compute and store predictions for each audio sample\n",
        "for file_name in file_names:\n",
        "    if os.path.exists(predictions_dir + 'mood-' + file_name) and os.path.exists(predictions_dir + 'miscellaneous-' + file_name): # avoid recomputing\n",
        "        continue\n",
        "    # string manipulations to locate the audio file\n",
        "    file_name_dir = file_name.split('-')[-1].split('_')[0]\n",
        "    file_name_audio = file_name.split('_')[-1].split('.json')[0] \n",
        "    file_name_path = main_dir + \"17/\" + file_name_dir + \"/\" + file_name_audio\n",
        "\n",
        "    audio = EasyLoader(filename = file_name_path, sampleRate = 16000, endTime = 180)() # load audio\n",
        "\n",
        "    predictions_mood = {}\n",
        "    predictions_miscellaneous = {}\n",
        "    for root, dirs, files in os.walk(models_dir): # get model names\n",
        "        for file in files:\n",
        "              if file.endswith('vggish-audioset.pb'): # select source task\n",
        "                  model_name = os.path.join(root, file)\n",
        "                  model = file.split('-')[0]\n",
        "                  prediction = TensorflowPredictVGGish(graphFilename = model_name)(audio) # compute prediction using VGGish model\n",
        "                  prediction = np.mean(prediction, axis=0)\n",
        "                  # store predictions by groups \n",
        "                  if model in mood:\n",
        "                      predictions_mood[model] = prediction.tolist()\n",
        "                  elif model in miscellaneous:\n",
        "                      predictions_miscellaneous[model] = prediction.tolist()\n",
        "                  else:\n",
        "                      raise Exception(\"Invalid model\")\n",
        "    \n",
        "    # create json files with predictions\n",
        "    with open(predictions_dir + 'mood-' + file_name, 'w') as json_file_prediction:\n",
        "        json.dump(predictions_mood, json_file_prediction)\n",
        "    with open(predictions_dir + 'miscellaneous-' + file_name, 'w') as json_file_prediction: \n",
        "        json.dump(predictions_miscellaneous, json_file_prediction)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xy8vZtfYbIq3",
        "colab_type": "text"
      },
      "source": [
        "The next cell indicates the number of predictions that have been computed and stored so far."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PCiHHq_Mh9L",
        "colab_type": "code",
        "outputId": "e9d1b085-8b72-4131-fcfd-0deecf481e4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# number of vggish_audioset prediction files per target task group\n",
        "predictions_dir = main_dir + \"predictions/vggish_audioset/\"\n",
        "print( '{} vggish_audioset predictions stored'.format( len(os.listdir(predictions_dir))//2 ) )"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "565 vggish_audioset predictions stored\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}